{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 60\u001b[0m\n\u001b[0;32m     57\u001b[0m encoded_labels, num_classes \u001b[38;5;241m=\u001b[39m encode_labels(labels)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# Tokenize texts\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m tokenized_texts \u001b[38;5;241m=\u001b[39m \u001b[43mtokenize_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Convert tokenized texts and encoded labels to PyTorch tensors\u001b[39;00m\n\u001b[0;32m     63\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m tokenized_texts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[1;32mIn[1], line 28\u001b[0m, in \u001b[0;36mtokenize_texts\u001b[1;34m(texts, max_length)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenize_texts\u001b[39m(texts, max_length):\n\u001b[0;32m     27\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m BertTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert-base-multilingual-cased\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 28\u001b[0m     tokenized_texts \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax_length\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenized_texts\n",
      "File \u001b[1;32mc:\\Users\\debar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2602\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[1;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2600\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[0;32m   2601\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[1;32m-> 2602\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2604\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[1;32mc:\\Users\\debar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2660\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2657\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   2659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_valid_text_input(text):\n\u001b[1;32m-> 2660\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2661\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext input must of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2662\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor `List[List[str]]` (batch of pretokenized examples).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2663\u001b[0m     )\n\u001b[0;32m   2665\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_valid_text_input(text_pair):\n\u001b[0;32m   2666\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2667\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext input must of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2668\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor `List[List[str]]` (batch of pretokenized examples).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2669\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples)."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Load data from CSV file\n",
    "def load_data(csv_file_path):\n",
    "    data = pd.read_csv(csv_file_path)\n",
    "    texts = data['Transcription Text'].values\n",
    "    labels = data['Emotion Category'].values\n",
    "    return texts, labels\n",
    "\n",
    "# Encode labels\n",
    "def encode_labels(labels):\n",
    "    label_encoder = LabelEncoder()\n",
    "    encoded_labels = label_encoder.fit_transform(labels)\n",
    "    num_classes = len(label_encoder.classes_)\n",
    "    return encoded_labels, num_classes\n",
    "\n",
    "# Tokenize text using BERT tokenizer\n",
    "def tokenize_texts(texts, max_length):\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "    tokenized_texts = tokenizer(texts, padding='max_length', truncation=True, max_length=max_length, return_tensors='pt')\n",
    "    return tokenized_texts\n",
    "\n",
    "# Define the Transformer model\n",
    "class BengaliTransformer(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(BengaliTransformer, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.fc(pooled_output)\n",
    "        return logits\n",
    "\n",
    "# Define paths and parameters\n",
    "csv_file_path = r\"E:\\Project\\dataset\\Kuet\\KuetTransript.csv\"  # Replace with the actual path to your CSV file\n",
    "max_length = 128  # Maximum sequence length for BERT tokenizer\n",
    "learning_rate = 1e-5\n",
    "num_epochs = 5\n",
    "batch_size = 16\n",
    "\n",
    "# Load data from CSV file\n",
    "texts, labels = load_data(csv_file_path)\n",
    "\n",
    "# Encode labels\n",
    "encoded_labels, num_classes = encode_labels(labels)\n",
    "\n",
    "# Tokenize texts\n",
    "tokenized_texts = tokenize_texts(texts, max_length)\n",
    "\n",
    "# Convert tokenized texts and encoded labels to PyTorch tensors\n",
    "input_ids = tokenized_texts['input_ids']\n",
    "attention_mask = tokenized_texts['attention_mask']\n",
    "labels_tensor = torch.tensor(encoded_labels, dtype=torch.long)\n",
    "\n",
    "# Create dataset and data loader\n",
    "dataset = TensorDataset(input_ids, attention_mask, labels_tensor)\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize the model\n",
    "model = BengaliTransformer(num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch in data_loader:\n",
    "        input_ids_batch, attention_mask_batch, labels_batch = batch\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(input_ids_batch, attention_mask_batch)\n",
    "        loss = criterion(logits, labels_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(data_loader)}')\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7c17ab84c1840d98766d86aaff9c9da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\debar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\debar\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 1.5051577384011787\n",
      "Epoch [2/5], Loss: 1.3088188516466241\n",
      "Epoch [3/5], Loss: 1.187457843830711\n",
      "Epoch [4/5], Loss: 1.01839115954282\n",
      "Epoch [5/5], Loss: 0.8341191714270073\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Load data from CSV file\n",
    "def load_data(csv_file_path):\n",
    "    data = pd.read_csv(csv_file_path)\n",
    "    texts = data['Transcription Text'].astype(str).tolist()  # Convert to strings and then to list\n",
    "    labels = data['Emotion Category'].values\n",
    "    return texts, labels\n",
    "\n",
    "# Encode labels\n",
    "def encode_labels(labels):\n",
    "    label_encoder = LabelEncoder()\n",
    "    encoded_labels = label_encoder.fit_transform(labels)\n",
    "    num_classes = len(label_encoder.classes_)\n",
    "    return encoded_labels, num_classes\n",
    "\n",
    "# Tokenize text using BERT tokenizer\n",
    "def tokenize_texts(texts, max_length):\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "    tokenized_texts = tokenizer(texts, padding='max_length', truncation=True, max_length=max_length, return_tensors='pt')\n",
    "    return tokenized_texts\n",
    "\n",
    "# Define the Transformer model\n",
    "class BengaliTransformer(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(BengaliTransformer, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.fc(pooled_output)\n",
    "        return logits\n",
    "\n",
    "# Define paths and parameters\n",
    "csv_file_path = r\"E:\\Project\\dataset\\Kuet\\KuetTransript.csv\" # Replace with the actual path to your CSV file\n",
    "max_length = 128  # Maximum sequence length for BERT tokenizer\n",
    "learning_rate = 1e-5\n",
    "num_epochs = 5\n",
    "batch_size = 16\n",
    "\n",
    "# Load data from CSV file\n",
    "texts, labels = load_data(csv_file_path)\n",
    "\n",
    "# Encode labels\n",
    "encoded_labels, num_classes = encode_labels(labels)\n",
    "\n",
    "# Tokenize texts\n",
    "tokenized_texts = tokenize_texts(texts, max_length)\n",
    "\n",
    "# Convert tokenized texts and encoded labels to PyTorch tensors\n",
    "input_ids = tokenized_texts['input_ids']\n",
    "attention_mask = tokenized_texts['attention_mask']\n",
    "labels_tensor = torch.tensor(encoded_labels, dtype=torch.long)\n",
    "\n",
    "# Create dataset and data loader\n",
    "dataset = TensorDataset(input_ids, attention_mask, labels_tensor)\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize the model\n",
    "model = BengaliTransformer(num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch in data_loader:\n",
    "        input_ids_batch, attention_mask_batch, labels_batch = batch\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(input_ids_batch, attention_mask_batch)\n",
    "        loss = criterion(logits, labels_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(data_loader)}')\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Training Loss: 1.566067737340927\n",
      "Epoch [2/5], Training Loss: 1.3510129630565644\n",
      "Epoch [3/5], Training Loss: 1.2608307346701622\n",
      "Epoch [4/5], Training Loss: 1.1259834140539169\n",
      "Epoch [5/5], Training Loss: 0.9468737751245498\n",
      "Test Loss: 1.3043650653627183, Accuracy: 0.5238095238095238\n",
      "Finished Training and Evaluation\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Load data from CSV file\n",
    "def load_data(csv_file_path):\n",
    "    data = pd.read_csv(csv_file_path)\n",
    "    texts = data['Transcription Text'].astype(str).tolist()  # Convert to strings and then to list\n",
    "    labels = data['Emotion Category'].values\n",
    "    return texts, labels\n",
    "\n",
    "# Encode labels\n",
    "def encode_labels(labels):\n",
    "    label_encoder = LabelEncoder()\n",
    "    encoded_labels = label_encoder.fit_transform(labels)\n",
    "    num_classes = len(label_encoder.classes_)\n",
    "    return encoded_labels, num_classes\n",
    "\n",
    "# Tokenize text using BERT tokenizer\n",
    "def tokenize_texts(texts, max_length):\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "    tokenized_texts = tokenizer(texts, padding='max_length', truncation=True, max_length=max_length, return_tensors='pt')\n",
    "    return tokenized_texts\n",
    "\n",
    "# Define the Transformer model\n",
    "class BengaliTransformer(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(BengaliTransformer, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.fc(pooled_output)\n",
    "        return logits\n",
    "\n",
    "# Define paths and parameters\n",
    "csv_file_path = r\"E:\\Project\\dataset\\Kuet\\KuetTransript.csv\" # Replace with the actual path to your CSV file\n",
    "max_length = 128  # Maximum sequence length for BERT tokenizer\n",
    "learning_rate = 1e-5\n",
    "num_epochs = 5\n",
    "batch_size = 16\n",
    "\n",
    "# Load data from CSV file\n",
    "texts, labels = load_data(csv_file_path)\n",
    "\n",
    "# Encode labels\n",
    "encoded_labels, num_classes = encode_labels(labels)\n",
    "\n",
    "# Split data into train and test sets\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(texts, encoded_labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Tokenize texts\n",
    "train_tokenized_texts = tokenize_texts(train_texts, max_length)\n",
    "test_tokenized_texts = tokenize_texts(test_texts, max_length)\n",
    "\n",
    "# Convert tokenized texts and encoded labels to PyTorch tensors for train and test sets\n",
    "train_input_ids, train_attention_mask, train_labels_tensor = train_tokenized_texts['input_ids'], train_tokenized_texts['attention_mask'], torch.tensor(train_labels, dtype=torch.long)\n",
    "test_input_ids, test_attention_mask, test_labels_tensor = test_tokenized_texts['input_ids'], test_tokenized_texts['attention_mask'], torch.tensor(test_labels, dtype=torch.long)\n",
    "\n",
    "# Create train and test datasets and data loaders\n",
    "train_dataset = TensorDataset(train_input_ids, train_attention_mask, train_labels_tensor)\n",
    "test_dataset = TensorDataset(test_input_ids, test_attention_mask, test_labels_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialize the model\n",
    "model = BengaliTransformer(num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch in train_loader:\n",
    "        input_ids_batch, attention_mask_batch, labels_batch = batch\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(input_ids_batch, attention_mask_batch)\n",
    "        loss = criterion(logits, labels_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {running_loss/len(train_loader)}')\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids_batch, attention_mask_batch, labels_batch = batch\n",
    "        outputs = model(input_ids_batch, attention_mask_batch)\n",
    "        loss = criterion(outputs, labels_batch)\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_predictions += labels_batch.size(0)\n",
    "        correct_predictions += (predicted == labels_batch).sum().item()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct_predictions / total_predictions\n",
    "print(f'Test Loss: {test_loss/len(test_loader)}, Accuracy: {accuracy}')\n",
    "print('Finished Training and Evaluation')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#this is final "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\debar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Load data from CSV file\n",
    "def load_data(csv_file_path):\n",
    "    data = pd.read_csv(csv_file_path)\n",
    "    texts = data['Transcription Text'].astype(str).tolist()  # Convert to strings and then to list\n",
    "    labels = data['Emotion Category'].values\n",
    "    return texts, labels\n",
    "\n",
    "# Encode labels\n",
    "def encode_labels(labels):\n",
    "    label_encoder = LabelEncoder()\n",
    "    encoded_labels = label_encoder.fit_transform(labels)\n",
    "    num_classes = len(label_encoder.classes_)\n",
    "    return encoded_labels, num_classes\n",
    "\n",
    "# Tokenize text using BERT tokenizer\n",
    "def tokenize_texts(texts, max_length):\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "    tokenized_texts = tokenizer(texts, padding='max_length', truncation=True, max_length=max_length, return_tensors='pt')\n",
    "    return tokenized_texts\n",
    "\n",
    "# Define the Transformer model\n",
    "class BengaliTransformer(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(BengaliTransformer, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.fc(pooled_output)\n",
    "        return logits\n",
    "\n",
    "# Define paths and parameters\n",
    "csv_file_path = r\"E:\\Project\\dataset\\Kuet\\KuetTransript.csv\" # Replace with the actual path to your CSV file\n",
    "max_length = 128  # Maximum sequence length for BERT tokenizer\n",
    "learning_rate = 1e-5\n",
    "num_epochs = 5\n",
    "batch_size = 16\n",
    "\n",
    "# Load data from CSV file\n",
    "texts, labels = load_data(csv_file_path)\n",
    "\n",
    "# Encode labels\n",
    "encoded_labels, num_classes = encode_labels(labels)\n",
    "\n",
    "# Split data into train and test sets\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(texts, encoded_labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Tokenize texts\n",
    "train_tokenized_texts = tokenize_texts(train_texts, max_length)\n",
    "test_tokenized_texts = tokenize_texts(test_texts, max_length)\n",
    "\n",
    "# Convert tokenized texts and encoded labels to PyTorch tensors for train and test sets\n",
    "train_input_ids, train_attention_mask, train_labels_tensor = train_tokenized_texts['input_ids'], train_tokenized_texts['attention_mask'], torch.tensor(train_labels, dtype=torch.long)\n",
    "test_input_ids, test_attention_mask, test_labels_tensor = test_tokenized_texts['input_ids'], test_tokenized_texts['attention_mask'], torch.tensor(test_labels, dtype=torch.long)\n",
    "\n",
    "# Create train and test datasets and data loaders\n",
    "train_dataset = TensorDataset(train_input_ids, train_attention_mask, train_labels_tensor)\n",
    "test_dataset = TensorDataset(test_input_ids, test_attention_mask, test_labels_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialize the model\n",
    "model = BengaliTransformer(num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch in train_loader:\n",
    "        input_ids_batch, attention_mask_batch, labels_batch = batch\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(input_ids_batch, attention_mask_batch)\n",
    "        loss = criterion(logits, labels_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader)}')\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids_batch, attention_mask_batch, labels_batch = batch\n",
    "        outputs = model(input_ids_batch, attention_mask_batch)\n",
    "        loss = criterion(outputs, labels_batch)\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions.extend(predicted.tolist())\n",
    "        total_predictions += labels_batch.size(0)\n",
    "        correct_predictions += (predicted == labels_batch).sum().item()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct_predictions / total_predictions\n",
    "print(f'Test Loss: {test_loss/len(test_loader)}, Accuracy: {accuracy}')\n",
    "#Print Confussion matrix\n",
    "cm = confusion_matrix(test_labels, predictions)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "print(f'Total emotion levels in the confusion matrix: {len(classes)}')\n",
    "# Print classification report\n",
    "print(classification_report(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Loss: 1.5480897665023803\n",
      "Test Loss: 1.4422246085272894, Accuracy: 0.41025641025641024\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total emotion levels in the confusion matrix: 6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Load data from CSV file\n",
    "def load_data(csv_file_path):\n",
    "    data = pd.read_csv(csv_file_path)\n",
    "    texts = data['Transcription Text'].astype(str).tolist()  # Convert to strings and then to list\n",
    "    labels = data['Emotion Category'].values\n",
    "    return texts, labels\n",
    "\n",
    "# Encode labels\n",
    "def encode_labels(labels):\n",
    "    label_encoder = LabelEncoder()\n",
    "    encoded_labels = label_encoder.fit_transform(labels)\n",
    "    num_classes = len(label_encoder.classes_)\n",
    "    return encoded_labels, num_classes, label_encoder.classes_\n",
    "\n",
    "# Tokenize text using BERT tokenizer\n",
    "def tokenize_texts(texts, max_length):\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "    tokenized_texts = tokenizer(texts, padding='max_length', truncation=True, max_length=max_length, return_tensors='pt')\n",
    "    return tokenized_texts\n",
    "\n",
    "# Define the Transformer model\n",
    "class BengaliTransformer(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(BengaliTransformer, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.fc(pooled_output)\n",
    "        return logits\n",
    "\n",
    "# Define paths and parameters\n",
    "csv_file_path = r\"E:\\Project\\dataset\\Kuet\\KuetTransript.csv\" # Replace with the actual path to your CSV file\n",
    "max_length = 128  # Maximum sequence length for BERT tokenizer\n",
    "learning_rate = 1e-5\n",
    "num_epochs = 1\n",
    "batch_size = 16\n",
    "\n",
    "# Load data from CSV file\n",
    "texts, labels = load_data(csv_file_path)\n",
    "\n",
    "# Encode labels\n",
    "encoded_labels, num_classes, classes = encode_labels(labels)\n",
    "\n",
    "# Split data into train and test sets\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(texts, encoded_labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Tokenize texts\n",
    "train_tokenized_texts = tokenize_texts(train_texts, max_length)\n",
    "test_tokenized_texts = tokenize_texts(test_texts, max_length)\n",
    "\n",
    "# Convert tokenized texts and encoded labels to PyTorch tensors for train and test sets\n",
    "train_input_ids, train_attention_mask, train_labels_tensor = train_tokenized_texts['input_ids'], train_tokenized_texts['attention_mask'], torch.tensor(train_labels, dtype=torch.long)\n",
    "test_input_ids, test_attention_mask, test_labels_tensor = test_tokenized_texts['input_ids'], test_tokenized_texts['attention_mask'], torch.tensor(test_labels, dtype=torch.long)\n",
    "\n",
    "# Create train and test datasets and data loaders\n",
    "train_dataset = TensorDataset(train_input_ids, train_attention_mask, train_labels_tensor)\n",
    "test_dataset = TensorDataset(test_input_ids, test_attention_mask, test_labels_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialize the model\n",
    "model = BengaliTransformer(num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch in train_loader:\n",
    "        input_ids_batch, attention_mask_batch, labels_batch = batch\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(input_ids_batch, attention_mask_batch)\n",
    "        loss = criterion(logits, labels_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader)}')\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids_batch, attention_mask_batch, labels_batch = batch\n",
    "        outputs = model(input_ids_batch, attention_mask_batch)\n",
    "        loss = criterion(outputs, labels_batch)\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions.extend(predicted.tolist())\n",
    "        total_predictions += labels_batch.size(0)\n",
    "        correct_predictions += (predicted == labels_batch).sum().item()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct_predictions / total_predictions\n",
    "print(f'Test Loss: {test_loss/len(test_loader)}, Accuracy: {accuracy}')\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm = confusion_matrix(test_labels, predictions)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "print(f'Total emotion levels in the confusion matrix: {len(classes)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "best_loss = float('inf')\n",
    "early_stop_count = 0\n",
    "early_stop_at = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    if early_stop_count == early_stop_at:\n",
    "        break\n",
    "    else:\n",
    "        print('Epoch: {}/{}'.format(epoch+1, EPOCHS))\n",
    "        pbar = tf.keras.utils.Progbar(int(910/(batch_size)), width=30, interval=1)\n",
    "       \n",
    "        for step, (inp, tar) in enumerate(train_dataset):\n",
    "            train_step(inp, tar)\n",
    "            pbar.add(1, values=[(\"train_loss\", train_loss.result()) ])\n",
    "           \n",
    "        y_true_valid = []\n",
    "        y_pred_valid = []\n",
    "        print('Evaluating Validation Dataset')\n",
    "        for inp, tar in valid_dataset:\n",
    "            for x in tar.numpy():\n",
    "                for y in x:\n",
    "                    y_true_valid.append(Emo_Dict[y])\n",
    "\n",
    "            for z in model.predict(inp):\n",
    "                y_pred_valid.append(Emo_Dict[np.argmax(z)])\n",
    "\n",
    "        mfscore_valid = f1_score(y_true_valid, y_pred_valid, labels=Emo_Dict, average='macro')\n",
    "        valid_accuracy = accuracy_score(y_true_valid, y_pred_valid)\n",
    "       \n",
    "        y_true_test = []\n",
    "        y_pred_test = []\n",
    "        print('Evaluating Test Dataset')\n",
    "        for inp, tar in test_dataset:\n",
    "            for x in tar.numpy():\n",
    "                for y in x:\n",
    "                    y_true_test.append(Emo_Dict[y])\n",
    "\n",
    "            for z in model.predict(inp):\n",
    "                y_pred_test.append(Emo_Dict[np.argmax(z)])\n",
    "\n",
    "        mfscore_test = f1_score(y_true_test, y_pred_test, labels=Emo_Dict, average='macro')\n",
    "        test_accuracy = accuracy_score(y_true_test, y_pred_test)\n",
    "\n",
    "        print('Train Loss: {}, Macro F [Valid/Test]: {}/{}, Accuracy [Valid/Test]: {}/{}'.format(\n",
    "            round(float(train_loss.result()), 4), round(mfscore_valid, 4), round(mfscore_test, 4),\n",
    "            round(valid_accuracy, 4), round(test_accuracy, 4)))\n",
    "       \n",
    "        if float(mfscore_valid) >= best_f_score_valid:\n",
    "            print('Macro F-score [Valid]: {} \\nMacro F-score [Test]: {}'.format(\n",
    "                float(round(mfscore_valid, 4)), float(round(mfscore_test, 4))))\n",
    "           \n",
    "            ckpt_save_path = ckpt_manager.save()\n",
    "            print('Saving checkpoint for {} step(s) at {}'.format(optimizer.iterations.numpy(), ckpt_save_path))\n",
    "            early_stop_count = 0\n",
    "        else:\n",
    "            print('Macro F-score [Valid] did not improve.')\n",
    "            early_stop_count += 1\n",
    "            print('Score did not improve for {} epoch(s). Current Steps: {}'.format(\n",
    "                early_stop_count, optimizer.iterations.numpy()))\n",
    "\n",
    "        train_loss.reset_states()\n",
    "\n",
    "        print(\"------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Loss: 1.592503735423088\n",
      "Epoch [2/500], Loss: 1.3596587479114532\n",
      "Epoch [3/500], Loss: 1.2986100241541862\n",
      "Epoch [4/500], Loss: 1.2638954058289529\n",
      "Epoch [5/500], Loss: 1.2099256113171577\n",
      "Epoch [6/500], Loss: 1.1474254116415978\n",
      "Epoch [7/500], Loss: 1.1263876289129258\n",
      "Epoch [8/500], Loss: 1.07006174325943\n",
      "Epoch [9/500], Loss: 1.019976721704006\n",
      "Epoch [10/500], Loss: 0.9418805867433548\n",
      "Epoch [11/500], Loss: 0.913724485039711\n",
      "Epoch [12/500], Loss: 0.8636923499405385\n",
      "Epoch [13/500], Loss: 0.851862957328558\n",
      "Epoch [14/500], Loss: 0.8309367708861828\n",
      "Epoch [15/500], Loss: 0.7737457059323788\n",
      "Epoch [16/500], Loss: 0.7663751162588597\n",
      "Epoch [17/500], Loss: 0.753177696466446\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 147\u001b[0m\n\u001b[0;32m    145\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m    146\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m--> 147\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    148\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m], Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrunning_loss\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_loader)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\optim\\optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    383\u001b[0m             )\n\u001b[1;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\optim\\optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\optim\\adamw.py:187\u001b[0m, in \u001b[0;36mAdamW.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    174\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    176\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    177\u001b[0m         group,\n\u001b[0;32m    178\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    184\u001b[0m         state_steps,\n\u001b[0;32m    185\u001b[0m     )\n\u001b[1;32m--> 187\u001b[0m     \u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\optim\\adamw.py:339\u001b[0m, in \u001b[0;36madamw\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    337\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adamw\n\u001b[1;32m--> 339\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\optim\\adamw.py:419\u001b[0m, in \u001b[0;36m_single_tensor_adamw\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m    418\u001b[0m exp_avg\u001b[38;5;241m.\u001b[39mlerp_(grad, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[1;32m--> 419\u001b[0m \u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddcmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n\u001b[0;32m    422\u001b[0m     step \u001b[38;5;241m=\u001b[39m step_t\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Define the Transformer model\n",
    "class BengaliTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes, num_layers=6, embed_dim=128, num_heads=8, ff_dim=512, rate=0.1):\n",
    "        super(BengaliTransformer, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, embed_dim)\n",
    "        self.positional_encoding = PositionalEncoding(embed_dim)\n",
    "        self.transformer_blocks = nn.ModuleList([\n",
    "            TransformerBlock(embed_dim, num_heads, ff_dim, rate) for _ in range(num_layers)\n",
    "        ])\n",
    "        self.dropout = nn.Dropout(rate)\n",
    "        self.fc = nn.Linear(embed_dim, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.positional_encoding(x)\n",
    "        for transformer in self.transformer_blocks:\n",
    "            x = transformer(x)\n",
    "        x = self.dropout(x[:, 0, :])  # Take the first token's output\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return x\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.attention = nn.MultiheadAttention(embed_dim, num_heads)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(embed_dim, ff_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ff_dim, embed_dim)\n",
    "        )\n",
    "        self.layernorm1 = nn.LayerNorm(embed_dim)\n",
    "        self.layernorm2 = nn.LayerNorm(embed_dim)\n",
    "        self.dropout1 = nn.Dropout(rate)\n",
    "        self.dropout2 = nn.Dropout(rate)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        attention_out, _ = self.attention(x, x, x)\n",
    "        x = x + self.dropout1(attention_out)\n",
    "        x = self.layernorm1(x)\n",
    "        ffn_out = self.ffn(x)\n",
    "        x = x + self.dropout2(ffn_out)\n",
    "        x = self.layernorm2(x)\n",
    "        return x\n",
    "\n",
    "# Load data from CSV file\n",
    "def load_data(csv_file_path):\n",
    "    data = pd.read_csv(csv_file_path)\n",
    "    texts = data['Transcription Text'].astype(str).tolist()  # Convert to strings and then to list\n",
    "    labels = data['Emotion Category'].values\n",
    "    return texts, labels\n",
    "\n",
    "# Encode labels\n",
    "def encode_labels(labels):\n",
    "    label_encoder = LabelEncoder()\n",
    "    encoded_labels = label_encoder.fit_transform(labels)\n",
    "    num_classes = len(label_encoder.classes_)\n",
    "    return encoded_labels, num_classes, label_encoder.classes_\n",
    "\n",
    "# Tokenize text using BERT tokenizer\n",
    "def tokenize_texts(texts, vocab):\n",
    "    tokenizer = lambda x: [vocab[token] for token in x.split()]\n",
    "    tokenized_texts = [tokenizer(text) for text in texts]\n",
    "    return tokenized_texts\n",
    "\n",
    "# Define paths and parameters\n",
    "csv_file_path = r\"E:\\Project\\dataset\\Kuet\\KuetTransript.csv\"  # Replace with the actual path to your CSV file\n",
    "learning_rate = 1e-4\n",
    "num_epochs = 500\n",
    "batch_size = 16\n",
    "\n",
    "# Load data from CSV file\n",
    "texts, labels = load_data(csv_file_path)\n",
    "\n",
    "# Encode labels\n",
    "encoded_labels, num_classes, classes = encode_labels(labels)\n",
    "\n",
    "# Build vocabulary\n",
    "vocab = {}\n",
    "idx = 0\n",
    "for text in texts:\n",
    "    for token in text.split():\n",
    "        if token not in vocab:\n",
    "            vocab[token] = idx\n",
    "            idx += 1\n",
    "\n",
    "# Tokenize texts\n",
    "tokenized_texts = tokenize_texts(texts, vocab)\n",
    "\n",
    "# Pad tokenized sequences\n",
    "max_len = max(len(seq) for seq in tokenized_texts)\n",
    "padded_texts = [seq + [0] * (max_len - len(seq)) for seq in tokenized_texts]\n",
    "\n",
    "# Convert tokenized texts and encoded labels to PyTorch tensors for train and test sets\n",
    "text_tensor = torch.tensor(padded_texts, dtype=torch.long)\n",
    "label_tensor = torch.tensor(encoded_labels, dtype=torch.long)\n",
    "\n",
    "# Create train and test datasets and data loaders\n",
    "dataset = TensorDataset(text_tensor, label_tensor)\n",
    "train_size = int(0.7 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialize the model\n",
    "model = BengaliTransformer(input_dim=len(vocab), num_classes=num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch in train_loader:\n",
    "        inputs, labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader)}')\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        inputs, labels = batch\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions.extend(predicted.tolist())\n",
    "        total_predictions += labels.size(0)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct_predictions / total_predictions\n",
    "print(f'Test Loss: {test_loss/len(test_loader)}, Accuracy: {accuracy}')\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm = confusion_matrix(encoded_labels[train_size:], predictions)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "print(f'Total emotion levels in the confusion matrix: {len(classes)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Final model for text dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\debar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 1.5555334717035294\n",
      "Epoch [2/5], Loss: 1.3396438390016556\n",
      "Epoch [3/5], Loss: 1.2503081306815147\n",
      "Epoch [4/5], Loss: 1.1245456755161285\n",
      "Epoch [5/5], Loss: 0.9241461403667927\n",
      "Test Loss: 1.305381589465671, Accuracy: 0.5421245421245421\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.75      0.58        63\n",
      "           1       0.43      0.47      0.45        49\n",
      "           2       0.44      0.26      0.33        31\n",
      "           3       0.18      0.11      0.13        28\n",
      "           4       0.55      0.39      0.45        57\n",
      "           5       1.00      1.00      1.00        45\n",
      "\n",
      "    accuracy                           0.54       273\n",
      "   macro avg       0.51      0.49      0.49       273\n",
      "weighted avg       0.53      0.54      0.52       273\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Load data from CSV file\n",
    "def load_data(csv_file_path):\n",
    "    data = pd.read_csv(csv_file_path)\n",
    "    texts = data['Transcription Text'].astype(str).tolist()  # Convert to strings and then to list\n",
    "    labels = data['Emotion Category'].values\n",
    "    return texts, labels\n",
    "\n",
    "# Encode labels\n",
    "def encode_labels(labels):\n",
    "    label_encoder = LabelEncoder()\n",
    "    encoded_labels = label_encoder.fit_transform(labels)\n",
    "    num_classes = len(label_encoder.classes_)\n",
    "    return encoded_labels, num_classes\n",
    "\n",
    "# Tokenize text using BERT tokenizer\n",
    "def tokenize_texts(texts, max_length):\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "    tokenized_texts = tokenizer(texts, padding='max_length', truncation=True, max_length=max_length, return_tensors='pt')\n",
    "    return tokenized_texts\n",
    "\n",
    "# Define the Transformer model\n",
    "class BengaliTransformer(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(BengaliTransformer, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.fc(pooled_output)\n",
    "        return logits\n",
    "\n",
    "# Define paths and parameters\n",
    "csv_file_path = r\"E:\\Project\\dataset\\Kuet\\KuetTransript.csv\" # Replace with the actual path to your CSV file\n",
    "max_length = 128  # Maximum sequence length for BERT tokenizer\n",
    "learning_rate = 1e-5\n",
    "num_epochs = 5\n",
    "batch_size = 16\n",
    "\n",
    "# Load data from CSV file\n",
    "texts, labels = load_data(csv_file_path)\n",
    "\n",
    "# Encode labels\n",
    "encoded_labels, num_classes = encode_labels(labels)\n",
    "\n",
    "# Split data into train and test sets\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(texts, encoded_labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Tokenize texts\n",
    "train_tokenized_texts = tokenize_texts(train_texts, max_length)\n",
    "test_tokenized_texts = tokenize_texts(test_texts, max_length)\n",
    "\n",
    "# Convert tokenized texts and encoded labels to PyTorch tensors for train and test sets\n",
    "train_input_ids, train_attention_mask, train_labels_tensor = train_tokenized_texts['input_ids'], train_tokenized_texts['attention_mask'], torch.tensor(train_labels, dtype=torch.long)\n",
    "test_input_ids, test_attention_mask, test_labels_tensor = test_tokenized_texts['input_ids'], test_tokenized_texts['attention_mask'], torch.tensor(test_labels, dtype=torch.long)\n",
    "\n",
    "# Create train and test datasets and data loaders\n",
    "train_dataset = TensorDataset(train_input_ids, train_attention_mask, train_labels_tensor)\n",
    "test_dataset = TensorDataset(test_input_ids, test_attention_mask, test_labels_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialize the model\n",
    "model = BengaliTransformer(num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch in train_loader:\n",
    "        input_ids_batch, attention_mask_batch, labels_batch = batch\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(input_ids_batch, attention_mask_batch)\n",
    "        loss = criterion(logits, labels_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader)}')\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids_batch, attention_mask_batch, labels_batch = batch\n",
    "        outputs = model(input_ids_batch, attention_mask_batch)\n",
    "        loss = criterion(outputs, labels_batch)\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions.extend(predicted.tolist())\n",
    "        total_predictions += labels_batch.size(0)\n",
    "        correct_predictions += (predicted == labels_batch).sum().item()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct_predictions / total_predictions\n",
    "print(f'Test Loss: {test_loss/len(test_loader)}, Accuracy: {accuracy}')\n",
    "\n",
    "# Plot the confusion matrix                                                                                                                                                                                                                                                                 \n",
    "cm = confusion_matrix(test_labels, predictions)                                                                \n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(test_labels, predictions))\n",
    "                                                              "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
